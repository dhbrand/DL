{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Custom Estimator for a Convolutional Neural Network\n",
    "\n",
    "Hello intrepid reader! In this notebook, we'll will add a function that uses ```tf.layers``` to build a vanilla CNN. This should achieve around 99% accuracy on MNIST (there is still plenty of room to improve). Have a look at the ```build_cnn``` function where we define the model. Aside from that (and changing our preprocessing to no longer 'flatten' the images, and to add a color channel dimension), the code otherwise remains unchanged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imgs_input_fn(filenames, labels=None, perform_shuffle=False, repeat_count=1, batch_size=1):\n",
    "    def _parse_function(filename, label):\n",
    "        image_string = tf.read_file(filename)\n",
    "        image = tf.image.decode_jpeg(image_string, channels=1)\n",
    "        image.set_shape([None, None, None])\n",
    "        image = tf.image.resize_images(image, [64, 64])\n",
    "        image.set_shape([64, 64, 1])\n",
    "        d = dict(zip([input_name], [image])), label\n",
    "        return d\n",
    "    if labels is None:\n",
    "        labels = [0]*len(filenames)\n",
    "    labels = np.array(labels)\n",
    "    # Expand the shape of \"labels\" if necessory\n",
    "    if len(labels.shape) == 1:\n",
    "        labels = np.expand_dims(labels, axis=1)\n",
    "    filenames = tf.constant(filenames)\n",
    "    labels = tf.constant(labels)\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    if perform_shuffle:\n",
    "        # Randomizes input using a window of 256 elements (read into memory)\n",
    "        dataset = dataset.shuffle(buffer_size=256)\n",
    "    dataset = dataset.repeat(repeat_count)  # Repeats dataset this # times\n",
    "    dataset = dataset.batch(batch_size)  # Batch size to use\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    batch_features, batch_labels = iterator.get_next()\n",
    "    return batch_features, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the directory where the original\n",
    "# dataset was uncompressed\n",
    "original_dataset_dir = './morph/colorSubset'\n",
    "\n",
    "# The directory where we will\n",
    "# store our smaller dataset\n",
    "base_dir = './data/male_vs_female_300'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "train_male_dir = os.path.join(train_dir, 'male')\n",
    "train_female_dir = os.path.join(train_dir, 'female')\n",
    "test_male_dir = os.path.join(test_dir, 'male')\n",
    "test_female_dir = os.path.join(test_dir, 'female')\n",
    "\n",
    "input_name = 'x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "MALE_LABEL = 0\n",
    "FEMALE_LABEL = 1\n",
    "train_male = [os.path.join(train_male_dir, file_name) for file_name in os.listdir(train_male_dir)]\n",
    "train_female = [os.path.join(train_female_dir, file_name) for file_name in os.listdir(train_female_dir)]\n",
    "train_files = train_male + train_female\n",
    "train_labels = [MALE_LABEL]*len(train_male)+[FEMALE_LABEL]*len(train_female)\n",
    "train_files, train_labels = unison_shuffled_copies(train_files, train_labels)\n",
    "test_male = [os.path.join(test_male_dir, file_name) for file_name in os.listdir(test_male_dir)]\n",
    "test_female = [os.path.join(test_female_dir, file_name) for file_name in os.listdir(test_female_dir)]\n",
    "test_files = test_male + test_female\n",
    "test_labels = [MALE_LABEL]*len(test_male)+[FEMALE_LABEL]*len(test_female)\n",
    "test_files, test_labels = unison_shuffled_copies(test_files, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 64, 64, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAAJpElEQVR4nG1XSYwcVxn+/7dUV1V3TU/3bD2exR57LBGH2IodlIRIJEc4QSSQCBISUnLhwIFVIDggwRkUceGEFCS4cOLIGhJQREgcOybO4tjGntWenu6Z7q693vt/DtXd0+P4Hareq/rfv3zv3x6+BOUgAAYEABDDLwKYQQDQaDmajWgIAECNvwEi8OTeY8QPbDsaSgIQ4lC8AIDyzQBYPkq1eLhgkFDKQRAADEoAsEAADcATwiQADVlyKZxKPqCAhkogAB6ZIIf/oXwjjImG8o5mgsaACFByuHdETiAADJOQigkYgRFZClP+lgAAKIHG0AghjvSeGERUCJE7VhSZ8YQ5ohICAY52KYQSlrGG2Lc2Mrgm+uBN391PcbnY9WcibIJxBp61DChLUhqdgp0UjZnp97w7NSLx1OemvGTj9qud2N2t+6Sn0qnC0DGFBeB3JtcWsbcXH/YX9i9+8zGJZCgyyr/+yl3R4ehs08pAowDmEqwS22MMkqzY2ev6Mxd/7iEyMVOBRnLnnWtXNqeb5jSiQAbEsTcx4PcACBABgBnyYmf7jvfUz9bKY6QsA5k4lSwrXvvzG/lj4oyrCQGYRj5pQYxwBQCAyva/7jV+9JuTIzyk6N/Yhxjc4Avffya8HN/JDQDwhJ+DkFIiAjMycNzZUN7LLzoCS46somoQdbMoo8ajv/q6ubZ4K2IhhFA4pEBUMA4dGyc73mMvPT5xIjBdNP08a2lN4PzgSvLe9J6nhtoPQ0QRgAAWxpikE9Ya8GwTjtwCPa9cMIKe/8WP7fVGvQViZIG08igW9tNsO5uBXwc4YeDkkHRhhW50rn5m7hjBOHu09P3tA7mMVJjckDHGEA0p2VoLYFF8d7+SxteNBUBERAECccQAtRsNiuR8n/IkSWy5h2kUw0CEAk/WWrZPqRgyQMCSATMAd97eUW6+6Jo8y/IozgpiZiJmZk7T1FoiE34tFqZny4/Ds1SlBAJHk9JA/ToUIFUFiFItpSIAJrTYFx7lcNJYCgtJ8LCEV5MKpen1U7KUpVJJ1+W0KO0jozURSSdQCINjwSdG2nhWaOC9aPOQpfBdAUpaXXUAiCgnY02WH7RvTDeE3RUAQojhPgEAQ7hRq7wXYQ5lOklRZZ0egQIk5QviItu9QyKg7VJrIiICUEWpB5gTVz22XaQiq4i8v3/Yn191ndx6th30ap7kIkuyjZBVL02P7KaJulBjSzk4emG3vX0zL5qrm53z1qbv37vd7p+5tDw7pQmSXKUZ7C6W0FkAAGWHU61FATMtUbt77aM7osY284SaLg4+3mubwVuXHz+3sMa1E9akKG4tQg6AD1QmqzwrvVby/ocbzgW/yIVEy2E66Nt5sSBt+9VzNy7QmspjR3Q7DQCgIQM7zOTRnh6o+dqumZo7RYP9VLCnVnz6R3ug1Lx/oltsO+LTc6c385r0KBXjGqJGyclsVGN1SlshZ/630NuP42kZNpaKZMtoTPx+vLBi8u7Cpb9jIbOjcB5hUCjakJUmrLjTUXTnvU+96Xzh2ub6pSU3WVrq33hu49/52q3lCweRs4Zf3dxJtT0q1SUGEjKnjt5eA6s9c/6J/NzC/CPbK08Tm9kXXv/s3HPXksHUzvXlqqyfvbjVcQvnyJWVBZASrZqq7c6sF7pR58qAdC+ZfaQIdBZPzS3cqh4ux7DwZJA/cti5+DcpL9pcDJGbOIXAnx4cnAj9VX2/ZnRVLfaMQRMT18590KhyD9ebYPJ2t78eLicTPYIqEzqDkI1bh/1Ow/U9YXPphRlbKEzlkIILMaM/FRT97ka43TJnp6Mya/GovDMDAw+Cuk+9LHakqlSBzP2n61a2kl0r3TldIB2E4dZe/K23RHD7of2LNbXzXUh6mxvGItu46wBLDZ6+b6DgfLB/cH9rc0BbrbkTPI4kIFIMABZRsljKv3inuV2nmcAU9mBrpos5x+nK3gY4SqdFuLsVkzKPvnOVh63M2AQLEoFkONvTRWAgFeiEW92ra6tusn235ZtsTYeUHYapysKVxpd/ipUJA0pPZAtIN08IYCMOXF8X7U7j3TeehuivUyvPn9m46zOFUbse6crqwn90hccpbTKcwVxpGLeoZGFEKTxxa4Xebmw6QfVZ7ESpY0wxZdlg/b0/OccqhyIAHrpltwOInk7yK0uXcOtyOw6xJoLtuSeudgrfVLxDS/t/3GZrx/oPSxtOaBHVnDw5v9h47d1dpYxTc+O/LC618H5iyGSQZTviwUaTARCIAQAZoDeX60L68g+RPTVP1Rbciw5711ZXawcmVNzvkC3hP+qJ1XF+WZpLaqr/XjdF57JxVZia6tzU3c+f6Q4UMxSf7OgUj5ssBpCi08xcS7ZR9a2fkqw73u7OYXDYRoyDTme4H8tG88FmGwCsGsR1Cm31mUovN3nPMa45fdr2eVMRDQYk+BOle6wTERGRaHwkGIrKXMOfkYU86EbgtE6uVw6tlWlbGCorKRDR8KEe5KjfWwtI2LQhC99G89lCw82s4/QN3gtg2OEdw+BoigjAgbtts2rYbDTsibhyMDvv604SKWXiQTbbQ4KyXRkNHjIYmYagYPb2WUk5oBPK8L7hhseH3cgW1F8cAzDs2scMEGgYXygAa8XH6/H1s3GS1ttbvW2vWmQf9mh6q561DgQCAR/l9LEJsrxUBI7W8hCc3a30HjhZM12O2vVsh+5V/K0Zx/Hcymr1n5jMRzxxjXhhfKmonizYIoVRis5Hdj1oAx40Vm4+98Y+LpMFt76Uw8rSsnPtl4OZ1gg3wK8oIboybj251IsSm+YYh8YidRY/mOpxEkzlPZhuiExqd3HGnZufaVSFiBhf+d2ZeuKBAeVwfuq3P3lq2hpmyiUIQq1kuCzXe43+tIjc5kxu2TOiokUw2wocRwhF+KVv460fokRQzptvYfqioH5srbUgBRaZdD0QXiWtpkZLmUsEAlEBqAZSOwIIJS4ynfp9//kzvnqZNPFsbHw2SSUEUG5WFKIiJTtkISuIhn2xVkqpYeMHrBhA+6/f/IZygACVF2rfhpUahFaSU4kdaxE0EzigJCJZ9BxRcZWL8igErGPXXitjQWolhVRaK6110y08TDm3FpRyJVprUdQCrVV5Q3pYMLGoI0rlaK0tiWqjSLT0DaP0pYdKo/ADVan42pFajjr9B6NxhlALFEJIod1mFTPypS0KWziu1kprBZM3k4cEk1xtQ+QIRpROxmLgyQyUIBZCELqVqgq0rjLlAJM31cl8gPPJlNJKKZEWSsvMDOUxC8dxCEUlACcvbHE8p/wfkq1UMqc140MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64 at 0x10E7FB0B8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "next_batch = imgs_input_fn(test_files, labels=test_labels, perform_shuffle=True, batch_size=20)\n",
    "with tf.Session() as sess:\n",
    "    first_batch = sess.run(next_batch)\n",
    "x_d = first_batch[0]['x']\n",
    "\n",
    "print(x_d.shape)\n",
    "img = image.array_to_img(x_d[8])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1)\n[[0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]]\n"
     ]
    }
   ],
   "source": [
    "x_l = first_batch[1]\n",
    "print(x_l.shape)\n",
    "print(x_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function that defines our CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_cnn(features, mode):\n",
    "    \n",
    "    image_batch = features['x']\n",
    "    \n",
    "    with tf.name_scope(\"conv1\"):  \n",
    "        conv1 = tf.layers.conv2d(inputs=image_batch, filters=160, kernel_size=[3, 3],\n",
    "                                 padding='same', activation=tf.nn.relu)\n",
    "\n",
    "    with tf.name_scope(\"pool1\"):  \n",
    "        pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    with tf.name_scope(\"conv2\"):  \n",
    "        conv2 = tf.layers.conv2d(inputs=pool1, filters=80, kernel_size=[3, 3],\n",
    "                                 padding='same', activation=tf.nn.relu)\n",
    "\n",
    "    with tf.name_scope(\"pool2\"):  \n",
    "        pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    with tf.name_scope(\"dense\"):  \n",
    "        # The 'images' are now 7x7 (28 / 2 / 2), and we have 64 channels per image\n",
    "        pool2_flat = tf.reshape(pool2, [-1, 16 * 16 * 80])\n",
    "        dense = tf.layers.dense(inputs=pool2_flat, units=128, activation=tf.nn.relu)\n",
    "\n",
    "    with tf.name_scope(\"dropout\"):  \n",
    "        # Add dropout operation; 0.8 probability that a neuron will be kept\n",
    "        dropout = tf.layers.dropout(\n",
    "            inputs=dense, rate=0.2, training = mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    logits = tf.layers.dense(inputs=dropout, units=2)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write a Custom Estimator we'll specify our own model function. Here, we'll use ```tf.layers``` to replicate the model from the third notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    logits = build_cnn(features, mode)\n",
    "    \n",
    "    # Generate Predictions\n",
    "    classes = tf.argmax(logits, axis=1)\n",
    "    predictions = {\n",
    "        'classes': classes,\n",
    "        'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Return an EstimatorSpec for prediction\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "        \n",
    "    # Compute the loss, per usual.\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=labels, logits=logits)\n",
    "        \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        \n",
    "        # Configure the Training Op\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step(),\n",
    "            learning_rate=1e-3,\n",
    "            optimizer='Adam')\n",
    "\n",
    "        # Return an EstimatorSpec for training\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions,\n",
    "                                      loss=loss, train_op=train_op)    \n",
    "\n",
    "    assert mode == tf.estimator.ModeKeys.EVAL\n",
    "    \n",
    "    # Configure the accuracy metric for evaluation\n",
    "    metrics = {'accuracy': tf.metrics.accuracy(classes, tf.argmax(labels, axis=1))}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, \n",
    "                                      predictions=predictions, \n",
    "                                      loss=loss,\n",
    "                                      eval_metric_ops=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input functions, as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/fm/z2chdhwn5z3__xvw4bw758hm0000gn/T/tmpzdxkb1ga\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/fm/z2chdhwn5z3__xvw4bw758hm0000gn/T/tmpzdxkb1ga', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c29e7cfd0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn=model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (?, 2) and (?, 1) are incompatible",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-032a4975e15e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If you are running on a machine without a GPU, this can take some time to train.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m estimator.train(input_fn=lambda: imgs_input_fn(train_files,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                   \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                   \u001b[0mperform_shuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                   \u001b[0mrepeat_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    741\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 743\u001b[0;31m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    744\u001b[0m       \u001b[0;31m# Check if the user created a loss summary, and add one if they didn't.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m       \u001b[0;31m# We assume here that the summary is called 'loss'. If it is not, we will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'config'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-76ede2a2944a>\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Compute the loss, per usual.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     loss = tf.losses.softmax_cross_entropy(\n\u001b[0;32m---> 18\u001b[0;31m         onehot_labels=labels, logits=logits)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy\u001b[0;34m(onehot_labels, logits, weights, label_smoothing, scope, loss_collection, reduction)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0monehot_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabel_smoothing\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    751\u001b[0m     \"\"\"\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (?, 2) and (?, 1) are incompatible"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# If you are running on a machine without a GPU, this can take some time to train.\n",
    "estimator.train(input_fn=lambda: imgs_input_fn(train_files,\n",
    "                                  labels=train_labels,\n",
    "                                  perform_shuffle=True,\n",
    "                                  repeat_count=5,\n",
    "                                  batch_size=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-03-22-01:25:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/fm/z2chdhwn5z3__xvw4bw758hm0000gn/T/tmp8rir9g7u/model.ckpt-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-03-22-01:25:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1: accuracy = 1.0, global_step = 1, loss = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results\n   accuracy, was: 1.0\n   loss, was: 0.0\n   global_step, was: 1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the estimator using our input function.\n",
    "# We should see our accuracy metric below\n",
    "# Tweaking with the params of the model, you can get >99% accuracy\n",
    "evaluate_results = estimator.evaluate(input_fn=lambda: imgs_input_fn(test_files, \n",
    "                                   labels=test_labels, \n",
    "                                   perform_shuffle=False,\n",
    "                                   batch_size=1))\n",
    "print(\"Evaluation results\")\n",
    "for key in evaluate_results:\n",
    "    print(\"   {}, was: {}\".format(key, evaluate_results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here's how to print predictions on a few examples\n",
    "MAX_TO_PRINT = 5\n",
    "\n",
    "# This returns a generator object\n",
    "predictions = estimator.predict(input_fn=test_input)\n",
    "i = 0\n",
    "for p in predictions:\n",
    "    true_label = np.argmax(y_test[i])\n",
    "    predicted_label = p['classes']\n",
    "    print(\"Example %d. True: %d, Predicted: %s\" % (i, true_label, predicted_label))\n",
    "    i += 1\n",
    "    if i == MAX_TO_PRINT: break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
